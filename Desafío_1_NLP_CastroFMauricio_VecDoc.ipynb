{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "authorship_tag": "ABX9TyPDAjWuyNHmsCggkz3sche3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MauricioCastroF/NLP-desafios/blob/main/Desaf%C3%ADo_1_NLP_CastroFMauricio_VecDoc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "uUEHoMwez1dr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = np.array(['Podrá nublarse el sol eternamente', 'Podrá secarse en un instante el mar', 'Podrá romperse el eje de la Tierra como un débil cristal',\n",
        "                   \"Podrá la muerte Cubrirme con su fúnebre crespón\", \"Pero jamás en mí podrá apagarse la llama de tu amor\"])"
      ],
      "metadata": {
        "id": "c1M1nWyO0OuV"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***1 - Obtener el vocabulario del corpus (los términos utilizados)***\n",
        "*   Cada documento transformarlo en una lista de términos\n",
        "*   Armar un vector de términos no repetidos de todos los documentos"
      ],
      "metadata": {
        "id": "B5qgIfOQAA1k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformar cada documento en una lista de términos\n",
        "documentos = [doc.lower().split() for doc in corpus]"
      ],
      "metadata": {
        "id": "4baNCmxe9DsC"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Armar un vector de términos no repetidos de todos los documentos\n",
        "vocabulario = list(set([palabra for doc in documentos for palabra in doc]))"
      ],
      "metadata": {
        "id": "0lEHl1wr1l5X"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un diccionario para mapear cada término a un índice\n",
        "vocabulario_dict = {palabra: indice for indice, palabra in enumerate(vocabulario)}"
      ],
      "metadata": {
        "id": "4PtBsp6K2uoY"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imprimir el vocabulario\n",
        "print(\"Vocabulario:\")\n",
        "print(vocabulario)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y07pw1eU9eOK",
        "outputId": "5bf60681-67de-40c1-f355-5909b3429350"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulario:\n",
            "['pero', 'de', 'tu', 'mí', 'apagarse', 'el', 'su', 'amor', 'llama', 'cristal', 'podrá', 'como', 'eternamente', 'mar', 'con', 'un', 'romperse', 'eje', 'nublarse', 'sol', 'jamás', 'secarse', 'cubrirme', 'instante', 'tierra', 'crespón', 'muerte', 'fúnebre', 'débil', 'la', 'en']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertir los documentos a vectores de términos utilizando el vocabulario\n",
        "documentos_vectorizados = []\n",
        "for doc in documentos:\n",
        "    vector = np.zeros(len(vocabulario))\n",
        "    for palabra in doc:\n",
        "        if palabra in vocabulario_dict:\n",
        "            indice = vocabulario_dict[palabra]\n",
        "            vector[indice] += 1\n",
        "    documentos_vectorizados.append(vector)"
      ],
      "metadata": {
        "id": "HheGHiH09R3_"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertir los documentos vectorizados a tensores de PyTorch\n",
        "documentos_tensor = torch.tensor(documentos_vectorizados)"
      ],
      "metadata": {
        "id": "SA1mIbW89U5D"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#documentos vectorizados\n",
        "print(\"\\nDocumentos vectorizados:\")\n",
        "print(documentos_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kltmtJFl9ZPs",
        "outputId": "bfa5f905-5e45-4696-dda6-b7012fb2c1f0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Documentos vectorizados:\n",
            "tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
            "         1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0.,\n",
            "         0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1.,\n",
            "         0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0.],\n",
            "        [1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.]],\n",
            "       dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***2- OneHot encoding***\n",
        "Data una lista de textos, devolver una matriz con la representación oneHotEncoding de estos"
      ],
      "metadata": {
        "id": "CzBSDNbrANU7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# OneHot encoding\n",
        "onehot = []\n",
        "for documento in corpus:\n",
        "    vector = []\n",
        "    palabras = documento.lower().split()\n",
        "    for palabra in vocabulario:\n",
        "        if palabra in palabras:\n",
        "            vector.append(1)\n",
        "        else:\n",
        "            vector.append(0)\n",
        "    onehot.append(vector)"
      ],
      "metadata": {
        "id": "EDzxT5y8AQ0T"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imprimir los vectores OneHot\n",
        "print(\"Vectores OneHot:\")\n",
        "for vector in onehot:\n",
        "    print(vector)\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CP2AdACzAacY",
        "outputId": "736c3c86-9606-49de-8415-3b63929b2a58"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vectores OneHot:\n",
            "[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1]\n",
            "[0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0]\n",
            "[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0]\n",
            "[1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***3- Vectores de frecuencia***\n",
        "Data una lista de textos, devolver una matriz con la representación de frecuencia de estos"
      ],
      "metadata": {
        "id": "8yyyCCYAAenK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectores de frecuencia\n",
        "vectores_frecuencia = []\n",
        "for documento in corpus:\n",
        "    vector = []\n",
        "    palabras = documento.lower().split()\n",
        "    for palabra in vocabulario:\n",
        "        vector.append(palabras.count(palabra))\n",
        "    vectores_frecuencia.append(vector)"
      ],
      "metadata": {
        "id": "5XwtVo_tAnWo"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imprimir los vectores de frecuencia\n",
        "print(\"Vectores de frecuencia:\")\n",
        "for vector in vectores_frecuencia:\n",
        "    print(vector)\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYU8XTBYAoEx",
        "outputId": "f879538c-fb5d-4bad-8051-4ebb5fd535e5"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vectores de frecuencia:\n",
            "[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1]\n",
            "[0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0]\n",
            "[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0]\n",
            "[1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***4- TF-IDF***\n",
        "Data una lista de textos, devolver una matriz con la representacion TFIDF"
      ],
      "metadata": {
        "id": "jEFibMBYArl_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para obtener los vectores TF-IDF de un corpus\n",
        "def get_tfidf_vectors(corpus):\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    X = vectorizer.fit_transform(corpus)\n",
        "    tfidf_vectors = X.toarray()\n",
        "    return tfidf_vectors"
      ],
      "metadata": {
        "id": "nIS_u8QVDV61"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TF-IDF\n",
        "import math"
      ],
      "metadata": {
        "id": "Vh98VF5zAxUO"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idf = {}\n",
        "for palabra in vocabulario:\n",
        "    df = sum([palabra in documento.lower().split() for documento in corpus])\n",
        "    idf[palabra] = math.log(len(corpus) / (1 + df))\n",
        "\n",
        "vectores_tfidf = []\n",
        "for documento in corpus:\n",
        "    vector = []\n",
        "    palabras = documento.lower().split()\n",
        "    for palabra in vocabulario:\n",
        "        tf = palabras.count(palabra)\n",
        "        vector.append(tf * idf[palabra])\n",
        "    vectores_tfidf.append(vector)"
      ],
      "metadata": {
        "id": "RaReGHNtA1Pf"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imprimir los vectores TF-IDF\n",
        "print(\"Vectores TF-IDF:\")\n",
        "for vector in vectores_tfidf:\n",
        "    print(vector)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isIh2HfcA484",
        "outputId": "e62304e3-2555-4dac-dd5c-f31928a8d0ce"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vectores TF-IDF:\n",
            "[0.0, 0.0, 0.0, 0.0, 0.0, 0.22314355131420976, 0.0, 0.0, 0.0, 0.0, -0.1823215567939546, 0.0, 0.9162907318741551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9162907318741551, 0.9162907318741551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "[0.0, 0.0, 0.0, 0.0, 0.0, 0.22314355131420976, 0.0, 0.0, 0.0, 0.0, -0.1823215567939546, 0.0, 0.0, 0.9162907318741551, 0.0, 0.5108256237659907, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9162907318741551, 0.0, 0.9162907318741551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5108256237659907]\n",
            "[0.0, 0.5108256237659907, 0.0, 0.0, 0.0, 0.22314355131420976, 0.0, 0.0, 0.0, 0.9162907318741551, -0.1823215567939546, 0.9162907318741551, 0.0, 0.0, 0.0, 0.5108256237659907, 0.9162907318741551, 0.9162907318741551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9162907318741551, 0.0, 0.0, 0.0, 0.9162907318741551, 0.22314355131420976, 0.0]\n",
            "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9162907318741551, 0.0, 0.0, 0.0, -0.1823215567939546, 0.0, 0.0, 0.0, 0.9162907318741551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9162907318741551, 0.0, 0.0, 0.9162907318741551, 0.9162907318741551, 0.9162907318741551, 0.0, 0.22314355131420976, 0.0]\n",
            "[0.9162907318741551, 0.5108256237659907, 0.9162907318741551, 0.9162907318741551, 0.9162907318741551, 0.0, 0.0, 0.9162907318741551, 0.9162907318741551, 0.0, -0.1823215567939546, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9162907318741551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22314355131420976, 0.5108256237659907]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***5 - Comparación de documentos***\n",
        "Realizar una funcion que reciba el corpus y el índice de un documento y devuelva los documentos ordenados por la similitud coseno"
      ],
      "metadata": {
        "id": "CGG1n3V2A8qp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cosine_similarity(a, b):\n",
        "    return np.dot(a, b) / (np.linalg.norm(a) * (np.linalg.norm(b)))"
      ],
      "metadata": {
        "id": "RGTPGOdABlHF"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sort_documents_by_similarity(corpus, index):\n",
        "    tfidf_vectors = get_tfidf_vectors(corpus)\n",
        "    target_vector = tfidf_vectors[index]\n",
        "    similarities = []\n",
        "    for i, vector in enumerate(tfidf_vectors):\n",
        "        similarity = cosine_similarity(target_vector, vector)\n",
        "        similarities.append((i, similarity))\n",
        "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
        "    sorted_documents = [corpus[i] for i, _ in similarities]\n",
        "    return sorted_documents"
      ],
      "metadata": {
        "id": "m1kVFrE3B6JI"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_documents = sort_documents_by_similarity(corpus, 1)\n",
        "print(\"Documentos ordenados por similitud coseno:\")\n",
        "for document in sorted_documents:\n",
        "    print(document)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3oK3YVxNB9zu",
        "outputId": "8c9de96e-5d62-47c9-c8d4-fc6ef4dc5bdf"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Documentos ordenados por similitud coseno:\n",
            "Podrá secarse en un instante el mar\n",
            "Podrá romperse el eje de la Tierra como un débil cristal\n",
            "Podrá nublarse el sol eternamente\n",
            "Pero jamás en mí podrá apagarse la llama de tu amor\n",
            "Podrá la muerte Cubrirme con su fúnebre crespón\n"
          ]
        }
      ]
    }
  ]
}